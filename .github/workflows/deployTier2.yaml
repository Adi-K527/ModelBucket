name: "Deploy model Tier 2"


on:
    workflow_dispatch:
      inputs:
        filename:
          description: "name of model file"
          required: true
        secrettoken:
          description: "mb auth token"
          required: true
        project_id:
          description: "id of project"
          required: true
        model_id: 
          description: "id of model"
          required: true

env:
  AWS_REGION:            ${{ secrets.AWS_REGION }}
  ECR_REPOSITORY:        ${{ secrets.ECR_REPOSITORY }}
  ACCOUNT_ID:            ${{ secrets.ACCOUNT_ID }}
  AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  S3_BUCKET:             ${{ secrets.MB_BUCKET }}
  MODEL_FILES_BUCKET:    ${{ secrets.MODEL_FILES_BUCKET }}
  BACKEND_URL:           ${{ secrets.VITE_BACKEND_URI }}
  HETZNER_TOKEN:         ${{ secrets.HETZNER_TOKEN }}
  HETZNER_SSH_KEY:       ${{ secrets.HETZNER_SSH_KEY }}


jobs:
    deploy:
        name: Deploy
        runs-on: ubuntu-latest

        steps:
            - name: Create secret environment variables from inputs 
              run: |
                FILENAME=$(jq -r '.inputs.filename' $GITHUB_EVENT_PATH)
                echo ::add-mask::$FILENAME
                echo FILENAME="$FILENAME" >> $GITHUB_ENV
        
                MB_SECRET_TOKEN=$(jq -r '.inputs.secrettoken' $GITHUB_EVENT_PATH)
                echo ::add-mask::$MB_SECRET_TOKEN
                echo MB_SECRET_TOKEN="$MB_SECRET_TOKEN" >> $GITHUB_ENV
        
                PROJECT_ID=$(jq -r '.inputs.project_id' $GITHUB_EVENT_PATH)
                echo ::add-mask::$PROJECT_ID
                echo PROJECT_ID="$PROJECT_ID" >> $GITHUB_ENV
        
                MODEL_ID=$(jq -r '.inputs.model_id' $GITHUB_EVENT_PATH)
                echo ::add-mask::$MODEL_ID
                echo MODEL_ID="$MODEL_ID" >> $GITHUB_ENV

                echo ::add-mask::$SERVER_IPV4
                echo SERVER_IPV4="$SERVER_IPV4" >> $GITHUB_ENV

                echo ::add-mask::$SERVER_ID
                echo SERVER_ID="$SERVER_ID" >> $GITHUB_ENV
    
            - name: Checkout
              uses: actions/checkout@v4

            - name: Configure AWS credentials
              uses: aws-actions/configure-aws-credentials@0e613a0980cbf65ed5b322eb7a1e075d28913a83
              with:
                aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
                aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
                aws-region:            ${{ env.AWS_REGION }}
      
            - name: Login to Amazon ECR
              id: login-ecr
              uses: aws-actions/amazon-ecr-login@62f4f872db3836360b72999f4b87f1ff13310f3a

            - name: Install envsubst
              run: sudo apt-get install -y gettext-base

            - uses: hetznercloud/setup-hcloud@v1
            - run: |
                if hcloud server describe $FILENAME > /dev/null 2>&1; then
                  echo SERVER="true" >> $GITHUB_ENV
                else
                  echo SERVER="false" >> $GITHUB_ENV
                fi
              env:
                FILENAME:     ${{ env.FILENAME }}
                HCLOUD_TOKEN: ${{ env.HETZNER_TOKEN }}


            - uses: hetznercloud/setup-hcloud@v1
            - run: |
                if [ "$SERVER" = "false" ]; then
                  hcloud server create --name $FILENAME --image "ubuntu-20.04" --type "cx22" --ssh-key "hetzner_key"

                  SERVER_IPV4=$(hcloud server describe $FILENAME --output json | jq -r '.public_net.ipv4.ip')
                  echo ::add-mask::$SERVER_IPV4
                  echo SERVER_IPV4="$SERVER_IPV4" >> $GITHUB_ENV
                  echo "Instance has been created."

                else
                  SERVER_IPV4=$(hcloud server describe $FILENAME --output json | jq -r '.public_net.ipv4.ip')
                  echo ::add-mask::$SERVER_IPV4
                  echo SERVER_IPV4="$SERVER_IPV4" >> $GITHUB_ENV
                fi
              env:
                HCLOUD_TOKEN: ${{ env.HETZNER_TOKEN }}
                SERVER: ${{ env.SERVER }}
                FILENAME: ${{ env.FILENAME }}


            - name: Delete existing image
              id: delete-image-if-present
              run: |
                set -e
                echo "::add-mask::${{ env.FILENAME }}"
                if aws ecr describe-images --repository-name ${{ env.ECR_REPOSITORY }} --image-ids imageTag=${{ env.FILENAME }}-retrain --region us-east-1 > /dev/null 2>&1; then
                  aws ecr batch-delete-image --repository-name ${{ env.ECR_REPOSITORY }} --image-ids imageTag=${{ env.FILENAME }}-retrain --region us-east-1 > /dev/null 2>&1
                  aws ecr batch-delete-image --repository-name ${{ env.ECR_REPOSITORY }} --image-ids imageTag=${{ env.FILENAME }}-inference --region us-east-1 > /dev/null 2>&1
                fi
                  
            - name: Build, tag, and push image to Amazon ECR
              id: build-image
              env:
                ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
                IMAGE_TAG:    ${{ env.FILENAME }}
                AWS_REGION:   ${{ env.AWS_REGION }}
                AWS_ACCESS_KEY_ID:     ${{ env.AWS_ACCESS_KEY_ID }}
                AWS_SECRET_ACCESS_KEY: ${{ env.AWS_SECRET_ACCESS_KEY }}
                S3_BUCKET:  ${{ env.S3_BUCKET }}
                S3_KEY_REQ: ${{ env.FILENAME }}
              run: |
                echo "::add-mask::${{ env.IMAGE_TAG }}"
                docker build --build-arg AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID --build-arg AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY --build-arg AWS_DEFAULT_REGION=$AWS_REGION --build-arg S3_BUCKET=$S3_BUCKET --build-arg FILENAME=${{env.FILENAME}} --build-arg SERVICE=inference -t $ECR_REGISTRY/$ECR_REPOSITORY:${{env.IMAGE_TAG}}-inference ./deployments/Tier-2
                docker build --build-arg AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID --build-arg AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY --build-arg AWS_DEFAULT_REGION=$AWS_REGION --build-arg S3_BUCKET=$S3_BUCKET --build-arg FILENAME=${{env.FILENAME}} --build-arg SERVICE=retrain -t $ECR_REGISTRY/$ECR_REPOSITORY:${{env.IMAGE_TAG}}-retrain ./deployments/Tier-2
                docker push $ECR_REGISTRY/$ECR_REPOSITORY:${{env.IMAGE_TAG}}-inference
                echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:${{env.IMAGE_TAG}}-inference" >> $GITHUB_OUTPUT
                docker push $ECR_REGISTRY/$ECR_REPOSITORY:${{env.IMAGE_TAG}}-retrain
                echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:${{env.IMAGE_TAG}}-retrain" >> $GITHUB_OUTPUT

            - name: Retrieve kubeconfig from server
              uses: appleboy/scp-action@master
              with:
                host: ${{ env.SERVER_IPV4 }}
                key: ${{ env.HETZNER_SSH_KEY }}
                username: root
                source: "./deployments/Tier-2/kubernetes-config/"
                target: "./"

            - uses: webfactory/ssh-agent@v0.4.1
              with:
                ssh-private-key: ${{ env.HETZNER_SSH_KEY }}
            - run: |
                G_URL=$(ssh -o StrictHostKeyChecking=no root@${{ env.SERVER_IPV4 }} << 'EOF'
                  imageurl='${{env.ACCOUNT_ID}}.dkr.ecr.us-east-1.amazonaws.com/model_bucket_ecr:${{env.FILENAME}}-inference'
                  sed "s|\${IMAGE_URL}|$imageurl|g" deployments/Tier-2/kubernetes-config/inference-deployment.yaml > inference-deployment.yaml

                  imageurl='${{env.ACCOUNT_ID}}.dkr.ecr.us-east-1.amazonaws.com/model_bucket_ecr:${{env.FILENAME}}-retrain'
                  sed "s|\${IMAGE_URL}|$imageurl|g" deployments/Tier-2/kubernetes-config/retraining-deployment.yaml > retraining-deployment.yaml

                  if [ "${{env.SERVER}}" == "false" ]; then
                    sudo apt update 
                    sudo apt upgrade -y

                    curl -sfL https://get.k3s.io | sh -

                    sudo apt install -y docker.io
                    snap install aws-cli --classic

                    export AWS_ACCESS_KEY_ID="${{ env.AWS_ACCESS_KEY_ID }}"
                    export AWS_SECRET_ACCESS_KEY="${{ env.AWS_SECRET_ACCESS_KEY }}"
                    export AWS_DEFAULT_REGION="us-east-1"

                    docker login -u AWS -p $(aws ecr get-login-password) ${{ env.ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com
                    docker pull ${{ env.ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com/model_bucket_ecr:${{ env.FILENAME }}-inference
                    docker pull ${{ env.ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com/model_bucket_ecr:${{ env.FILENAME }}-retrain

                    cat /etc/rancher/k3s/k3s.yaml | base64 > kubeconfig.txt

                    ACCOUNT=$(aws sts get-caller-identity --query 'Account' --output text)
                    REGION=us-east-1
                    SECRET_NAME=${REGION}-ecr-registry
                    EMAIL=abc@xyz.com
                    TOKEN=`aws ecr --region=$REGION get-authorization-token --output text --query authorizationData[].authorizationToken | base64 -d | cut -d: -f2`
                    kubectl delete secret --ignore-not-found $SECRET_NAME
                    kubectl create secret docker-registry $SECRET_NAME \
                    --docker-server=https://$ACCOUNT.dkr.ecr.${REGION}.amazonaws.com \
                    --docker-username=AWS \
                    --docker-password="${TOKEN}" \
                    --docker-email="${EMAIL}"
                    
                    kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.14.8/config/manifests/metallb-native.yaml
                    kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.2.1/deploy/static/provider/cloud/deploy.yaml
                    kubectl apply -f deployments/Tier-2/kubernetes-config/metallb.yaml
                    kubectl apply -f deployments/Tier-2/kubernetes-config/ModelVolume.yaml
                    kubectl apply -f deployments/Tier-2/kubernetes-config/ModelVolumeClaim.yaml
                    kubectl create -f inference-deployment.yaml
                    kubectl create -f retraining-deployment.yaml
                    kubectl create -f deployments/Tier-2/kubernetes-config/inference-service.yaml
                    kubectl create -f deployments/Tier-2/kubernetes-config/retraining-service.yaml
                    sleep 30
                    kubectl apply -f deployments/Tier-2/kubernetes-config/ingress.yaml
                    sleep 10
                    kubectl apply -f deployments/Tier-2/kubernetes-config/ingress.yaml

                    snap install helm --classic
                    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
                    helm repo update
                    helm install prometheus prometheus-community/kube-prometheus-stack
                    sleep 3
                    kubectl port-forward --address 0.0.0.0 service/prometheus-kube-prometheus-prometheus 9090 > /dev/null 2>&1 &

                    docker run -d -p 3000:3000 \
                      --name grafana-abcd \
                      -e GF_SECURITY_ADMIN_PASSWORD=admin \
                      -e GF_SECURITY_DISABLE_INITIAL_ADMIN_PASSWORD_CHANGE=true \
                      -e GF_SECURITY_ALLOW_EMBEDDING=true \
                      -e GF_SECURITY_COOKIE_SAMESITE=disabled \
                      -e GF_AUTH_ANONYMOUS_ENABLED=true \
                      -e GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer \
                      -e GF_AUTH_ANONYMOUS_ORG_NAME="Main Org." \
                      grafana/grafana-oss
                    
                    GRAFANA_URL="http://localhost:3000"
                    GRAFANA_USER="admin"
                    GRAFANA_PASSWORD="admin"

                    API_KEY=$(curl -s -u "$GRAFANA_USER:$GRAFANA_PASSWORD" -X POST "$GRAFANA_URL/api/auth/keys" \
                        -H "Content-Type: application/json" \
                        -d '{"name": "api_key_5", "role": "Admin"}' | jq -r '.key')

                    echo "API Key: $API_KEY"

                    curl -H "Authorization: Bearer $API_KEY" \
                        -H "Content-Type: application/json" \
                        -X POST http://localhost:3000/api/datasources \
                        -d '{"name":"prometheus", "type":"prometheus", "url":"http://${{ env.SERVER_IPV4 }}:9090", "access":"proxy", "basicAuth":false}'

                    G_URL=$(curl -H "Authorization: Bearer $API_KEY" \
                        -H "Content-Type: application/json" \
                        -X POST http://localhost:3000/api/dashboards/db \
                        -d @/deployments/Tier-2/dashboard-config.json | jq -r '.url')

                    chmod 777 deployments/Tier-2/keep-prom-alive.sh
                    ./keep-prom-alive.sh > /dev/null 2>&1 &
                  else
                    export AWS_ACCESS_KEY_ID="${{ env.AWS_ACCESS_KEY_ID }}"
                    export AWS_SECRET_ACCESS_KEY="${{ env.AWS_SECRET_ACCESS_KEY }}"
                    export AWS_DEFAULT_REGION="us-east-1"

                    docker login -u AWS -p $(aws ecr get-login-password) ${{ env.ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com
                    docker pull ${{ env.ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com/model_bucket_ecr:${{ env.FILENAME }}-inference
                    docker pull ${{ env.ACCOUNT_ID }}.dkr.ecr.us-east-1.amazonaws.com/model_bucket_ecr:${{ env.FILENAME }}-retrain

                    cat /etc/rancher/k3s/k3s.yaml | base64 > kubeconfig.txt

                    ACCOUNT=$(aws sts get-caller-identity --query 'Account' --output text)
                    REGION=us-east-1
                    SECRET_NAME=${REGION}-ecr-registry
                    EMAIL=abc@xyz.com
                    TOKEN=`aws ecr --region=$REGION get-authorization-token --output text --query authorizationData[].authorizationToken | base64 -d | cut -d: -f2`
                    kubectl delete secret --ignore-not-found $SECRET_NAME
                    kubectl create secret docker-registry $SECRET_NAME \
                    --docker-server=https://$ACCOUNT.dkr.ecr.${REGION}.amazonaws.com \
                    --docker-username=AWS \
                    --docker-password="${TOKEN}" \
                    --docker-email="${EMAIL}"

                    [ -e /vol/model.joblib ] && rm /vol/model.joblib
                    [ -e /vol/preprocessor.joblib ] && rm /vol/preprocessor.joblib
                    kubectl delete deployment inference-deployment
                    kubectl delete deployment retrain-app-deployment
                    kubectl create -f inference-deployment.yaml
                    kubectl create -f retraining-deployment.yaml
                  fi

                  echo $G_URL

                EOF)
                
                echo ::add-mask::$G_URL 
                echo G_URL ="$G_URL " >> $GITHUB_ENV

            - name: Update Model State
              id: update-model
              env:
                FILENAME:              ${{ env.FILENAME }}
                MB_SECRET_TOKEN:       ${{ env.MB_SECRET_TOKEN }}
                PROJECT_ID:            ${{ env.PROJECT_ID }}
                MODEL_ID:              ${{ env.MODEL_ID }}
                BACKEND_URL:           ${{ env.BACKEND_URL }}
                G_URL:                 ${{ env.G_URL }}
              run: |
                set -e
                curl -X PUT \
                  -H "Content-Type: application/json"\
                  -d '{
                      "secretAccessToken": "${{ env.MB_SECRET_TOKEN }}",
                      "project_id":        "${{ env.PROJECT_ID }}",
                      "model_id":          "${{ env.MODEL_ID }}",
                      "state":             "ACTIVE",
                      "model_url":         "http://${{ env.SERVER_IPV4 }}/predict"
                      "grafana_url":       "http://${{ env.SERVER_IPV4 }}:3000${{ env.G_URL }}?theme=light"
                  }' \
                  "${{ env.BACKEND_URL }}/api/model/update"